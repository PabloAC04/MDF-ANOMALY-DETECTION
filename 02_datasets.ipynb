{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02159a9",
   "metadata": {},
   "source": [
    "# üìÇ Cap√≠tulo 2 - Datasets de Referencia y Comparaci√≥n de Modelos\n",
    "\n",
    "Tras la introducci√≥n conceptual al problema de la detecci√≥n de anomal√≠as, este cap√≠tulo se centra en los **datasets que servir√°n de base para la validaci√≥n y comparaci√≥n de modelos**.  \n",
    "\n",
    "Dado que los datos procedentes de archivos `.MDF` no cuentan con etiquetas fiables ni anotaciones de anomal√≠as, resulta necesario apoyarse en **conjuntos de datos de referencia** que s√≠ disponen de se√±ales temporales y etiquetas de anomal√≠as previamente definidas. Estos datasets permitir√°n evaluar los algoritmos en un entorno controlado antes de trasladar los m√©todos a se√±ales m√°s complejas y sin etiquetas.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Datasets utilizados\n",
    "\n",
    "Los datasets seleccionados provienen de distintos dominios (procesos industriales, redes de sensores y series sint√©ticas), lo cual aporta diversidad y robustez a la validaci√≥n:\n",
    "\n",
    "- **BATADAL** ‚Üí se√±ales de una planta de agua potable, con periodos normales y bajo ataque.  \n",
    "- **SKAB** ‚Üí datos de control industrial con v√°lvulas, incluye escenarios de funcionamiento normal y fallos.  \n",
    "- **WADI** ‚Üí simulaciones de un sistema de distribuci√≥n de agua con m√∫ltiples ataques cibern√©ticos.  \n",
    "- **EbayRanSynCoders** ‚Üí dataset sint√©tico con patrones aleatorios y anomal√≠as inyectadas.  \n",
    "- **SMAP** ‚Üí telemetr√≠a de sat√©lites, con etiquetas de anomal√≠as reales.  \n",
    "- **MSL** ‚Üí telemetr√≠a del sat√©lite *Mars Science Laboratory*, tambi√©n con anotaciones de anomal√≠as.  \n",
    "\n",
    "Cada uno de estos conjuntos se dividir√° en **entrenamiento, validaci√≥n y prueba**, garantizando consistencia en los experimentos.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Consideraciones sobre licencias y distribuci√≥n de datasets\n",
    "\n",
    "Los datasets empleados en este trabajo provienen de fuentes abiertas y repositorios p√∫blicos.  \n",
    "A continuaci√≥n se detallan sus or√≠genes y las licencias asociadas:\n",
    "\n",
    "| Dataset             | Fuente                                                                                      | Licencia                                                                 | Uso permitido en el trabajo |\n",
    "|---------------------|---------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|-----------------------------|\n",
    "| **SKAB**            | [Kaggle - Skoltech Anomaly Benchmark](https://www.kaggle.com/datasets/yuriykatser/skoltech-anomaly-benchmark-skab) | GNU Affero General Public License 3.0 (AGPL-3.0)                          | ‚úÖ Se puede usar y citar, **no redistribuir los datos en repositorios cerrados**. |\n",
    "| **CATS**            | [Kaggle - Controlled Anomalies Time Series](https://www.kaggle.com/datasets/patrickfleith/controlled-anomalies-time-series-dataset) | Creative Commons Attribution 4.0 (CC BY 4.0)                              | ‚úÖ Libre uso y redistribuci√≥n, siempre que se cite la fuente. |\n",
    "| **WaDI**            | iTrust, Singapore University of Technology and Design                                       | Propiedad iTrust (descarga acad√©mica con registro)                        | ‚úÖ Uso permitido para investigaci√≥n acad√©mica. No redistribuir. |\n",
    "| **BATADAL**         | iTrust, Singapore University of Technology and Design                                       | Propiedad iTrust (descarga acad√©mica con registro)                        | ‚úÖ Uso permitido para investigaci√≥n acad√©mica. No redistribuir. |\n",
    "| **Ebay RANSynCoders** | [GitHub - eBay RANSynCoders](https://github.com/eBay/RANSynCoders)                         | BSD License (Copyright ¬© 2021 eBay Inc.)                                  | ‚úÖ Uso, modificaci√≥n y redistribuci√≥n permitida con atribuci√≥n y disclaimers. |\n",
    "| **SMAP & MSL**      | [Kaggle - NASA Anomaly Detection Datasets](https://www.kaggle.com/datasets/patrickfleith/nasa-anomaly-detection-dataset-smap-msl) | Datos originales ¬© autores de NASA. Redistribuidos en Kaggle.             | ‚úÖ Uso acad√©mico permitido con cita. Redistribuci√≥n limitada. |\n",
    "\n",
    "### üìå Implicaciones pr√°cticas\n",
    "\n",
    "- En este trabajo **se describen y utilizan** los datasets, pero **no se redistribuyen directamente los ficheros originales**.  \n",
    "- Para su acceso, se proporcionan los enlaces oficiales de descarga.  \n",
    "- El procesamiento intermedio realizado (conversi√≥n a `.parquet` mediante la clase `DatasetsToParquet`) **no altera el contenido original**, solo su formato, y por tanto no modifica los t√©rminos de las licencias.  \n",
    "- Los gr√°ficos, tablas y resultados generados a partir de los datasets **s√≠ pueden incluirse libremente en este trabajo**, siempre citando la fuente correspondiente.  \n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Unificaci√≥n y Preprocesado\n",
    "\n",
    "Con el fin de trabajar de manera homog√©nea con todos los datasets, se desarroll√≥ una clase en Python llamada **`DatasetsToParquet`**, cuyo objetivo es:\n",
    "\n",
    "1. **Cargar** los datos originales desde su formato nativo (CSV, NPY, etc.).  \n",
    "2. **Estandarizar** columnas clave como `timestamp` y `anomaly`.  \n",
    "3. **Dividir** los datos en *training*, *validation* y *test* (con un split 60%-40% en validaci√≥n y prueba).  \n",
    "4. **Guardar** los resultados en formato **`.parquet`**, lo que facilita el acceso eficiente y la compatibilidad con librer√≠as como `pandas` y `pyarrow`.\n",
    "\n",
    "De esta manera, todos los conjuntos quedan listos para ser utilizados en la evaluaci√≥n de algoritmos, reduciendo la complejidad derivada de la heterogeneidad de los formatos originales.\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Inspecci√≥n de Datos Procesados\n",
    "\n",
    "Adicionalmente, se implement√≥ la funci√≥n **`inspect_parquet`**, que permite verificar el correcto procesamiento de cada dataset y obtener un resumen inicial:\n",
    "\n",
    "- N√∫mero de filas y columnas.  \n",
    "- Conteo y porcentaje de anomal√≠as.  \n",
    "- Vista previa de las primeras observaciones.  \n",
    "\n",
    "Esto asegura que los datos se encuentran en un estado adecuado antes de iniciar los experimentos.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Consideraciones sobre la validaci√≥n en datos temporales\n",
    "\n",
    "Estos datasets contienen **series temporales**, por lo que no es adecuado aplicar validaciones que mezclen pasado y futuro (p. ej., **k-fold** aleatorio o **bootstrap** est√°ndar), ya que introducir√≠an **fuga de informaci√≥n**.\n",
    "\n",
    "En su lugar, la validaci√≥n se plantea con **splits temporales que respetan el orden cronol√≥gico**. A lo largo del trabajo usaremos dos esquemas sencillos y pr√°cticos (descritos en detalle en el **Cap√≠tulo 4**):\n",
    "\n",
    "- **Time Series Cross-Validation (TSCV) con ventana creciente (*Expanding*)**: se entrena con un bloque inicial y, en cada split, se ampl√≠a el historial antes de validar en el siguiente tramo.  \n",
    "- **Walk-Forward con reentrenamiento**: se entrena con el bloque disponible, se valida en el siguiente y, tras evaluar, se incorpora ese bloque al entrenamiento antes de avanzar.\n",
    "\n",
    "De forma resumida, el flujo es:\n",
    "1. **Entrenamiento** (solo con datos pasados).  \n",
    "2. **Validaci√≥n** (evaluaci√≥n en el siguiente bloque temporal, sin mezclar futuro con pasado).  \n",
    "3. **Test** (medici√≥n final en datos no usados previamente).\n",
    "\n",
    "> Los detalles operativos (tama√±os de bloques, deslizamiento, limpieza previa de datos, etc.) se concretan en el **Cap√≠tulo 4**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Estrategias de comparaci√≥n de modelos\n",
    "\n",
    "Para comparar distintos enfoques de detecci√≥n de anomal√≠as, utilizaremos un conjunto de **m√©tricas complementarias**. La definici√≥n exacta y el modo de c√°lculo (a nivel de punto o de intervalo) se especifican en el **Cap√≠tulo 4**. Las m√©tricas incluyen:\n",
    "\n",
    "- **NAB Score (Numenta Anomaly Benchmark)** ‚Üí prioriza detecciones tempranas y penaliza falsas alarmas.  \n",
    "- **Precision, Recall y F1-score** ‚Üí calidad de detecci√≥n bajo umbral dado.  \n",
    "- **PR-AUC** ‚Üí √°rea bajo la curva *Precision‚ÄìRecall*, √∫til con clases desbalanceadas.  \n",
    "- **Tasa de falsas alarmas** (p. ej., por hora/d√≠a) ‚Üí estabilidad pr√°ctica.  \n",
    "- **Tiempo medio de detecci√≥n (MTTD)** ‚Üí rapidez al identificar el inicio de la anomal√≠a.\n",
    "\n",
    "Adem√°s, consideraremos la **consistencia entre datasets** (robustez) como indicador de generalizaci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Pr√≥ximos pasos\n",
    "\n",
    "En el siguiente cap√≠tulo se presentar√°n los **m√©todos de detecci√≥n** que se evaluar√°n sobre estos datasets. La **metodolog√≠a de validaci√≥n** y el **c√°lculo de m√©tricas** se detallan √≠ntegramente en el **Cap√≠tulo 4**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
