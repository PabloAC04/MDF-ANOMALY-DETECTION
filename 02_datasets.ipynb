{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02159a9",
   "metadata": {},
   "source": [
    "# üìÇ Cap√≠tulo 2 - Datasets de Referencia y Comparaci√≥n de Modelos\n",
    "\n",
    "Tras la introducci√≥n conceptual al problema de la detecci√≥n de anomal√≠as, este cap√≠tulo se centra en los **datasets que servir√°n de base para la validaci√≥n y comparaci√≥n de modelos**.  \n",
    "\n",
    "Dado que los datos procedentes de archivos `.MDF` no cuentan con etiquetas fiables ni anotaciones de anomal√≠as, resulta necesario apoyarse en **conjuntos de datos de referencia** que s√≠ disponen de se√±ales temporales y etiquetas de anomal√≠as previamente definidas. Estos datasets permitir√°n evaluar los algoritmos en un entorno controlado antes de trasladar los m√©todos a se√±ales m√°s complejas y sin etiquetas.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Datasets utilizados\n",
    "\n",
    "Los datasets seleccionados provienen de distintos dominios (procesos industriales, redes de sensores y series sint√©ticas), lo cual aporta diversidad y robustez a la validaci√≥n:\n",
    "\n",
    "- **BATADAL** ‚Üí se√±ales de una planta de agua potable, con periodos normales y bajo ataque.  \n",
    "- **SKAB** ‚Üí datos de control industrial con v√°lvulas, incluye escenarios de funcionamiento normal y fallos.  \n",
    "- **WADI** ‚Üí simulaciones de un sistema de distribuci√≥n de agua con m√∫ltiples ataques cibern√©ticos.  \n",
    "- **EbayRanSynCoders** ‚Üí dataset sint√©tico con patrones aleatorios y anomal√≠as inyectadas.  \n",
    "- **SMAP** ‚Üí telemetr√≠a de sat√©lites, con etiquetas de anomal√≠as reales.  \n",
    "- **MSL** ‚Üí telemetr√≠a del sat√©lite *Mars Science Laboratory*, tambi√©n con anotaciones de anomal√≠as.  \n",
    "\n",
    "Cada uno de estos conjuntos se dividir√° en **entrenamiento, validaci√≥n y prueba**, garantizando consistencia en los experimentos.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Consideraciones sobre licencias y distribuci√≥n de datasets\n",
    "\n",
    "Los datasets empleados en este trabajo provienen de fuentes abiertas y repositorios p√∫blicos.  \n",
    "A continuaci√≥n se detallan sus or√≠genes y las licencias asociadas:\n",
    "\n",
    "| Dataset             | Fuente                                                                                      | Licencia                                                                 | Uso permitido en el trabajo |\n",
    "|---------------------|---------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|-----------------------------|\n",
    "| **SKAB**            | [Kaggle - Skoltech Anomaly Benchmark](https://www.kaggle.com/datasets/yuriykatser/skoltech-anomaly-benchmark-skab) | GNU Affero General Public License 3.0 (AGPL-3.0)                          | ‚úÖ Se puede usar y citar, **no redistribuir los datos en repositorios cerrados**. |\n",
    "| **CATS**            | [Kaggle - Controlled Anomalies Time Series](https://www.kaggle.com/datasets/patrickfleith/controlled-anomalies-time-series-dataset) | Creative Commons Attribution 4.0 (CC BY 4.0)                              | ‚úÖ Libre uso y redistribuci√≥n, siempre que se cite la fuente. |\n",
    "| **WaDI**            | iTrust, Singapore University of Technology and Design                                       | Propiedad iTrust (descarga acad√©mica con registro)                        | ‚úÖ Uso permitido para investigaci√≥n acad√©mica. No redistribuir. |\n",
    "| **BATADAL**         | iTrust, Singapore University of Technology and Design                                       | Propiedad iTrust (descarga acad√©mica con registro)                        | ‚úÖ Uso permitido para investigaci√≥n acad√©mica. No redistribuir. |\n",
    "| **Ebay RANSynCoders** | [GitHub - eBay RANSynCoders](https://github.com/eBay/RANSynCoders)                         | BSD License (Copyright ¬© 2021 eBay Inc.)                                  | ‚úÖ Uso, modificaci√≥n y redistribuci√≥n permitida con atribuci√≥n y disclaimers. |\n",
    "| **SMAP & MSL**      | [Kaggle - NASA Anomaly Detection Datasets](https://www.kaggle.com/datasets/patrickfleith/nasa-anomaly-detection-dataset-smap-msl) | Datos originales ¬© autores de NASA. Redistribuidos en Kaggle.             | ‚úÖ Uso acad√©mico permitido con cita. Redistribuci√≥n limitada. |\n",
    "\n",
    "### üìå Implicaciones pr√°cticas\n",
    "\n",
    "- En este trabajo **se describen y utilizan** los datasets, pero **no se redistribuyen directamente los ficheros originales**.  \n",
    "- Para su acceso, se proporcionan los enlaces oficiales de descarga.  \n",
    "- El procesamiento intermedio realizado (conversi√≥n a `.parquet` mediante la clase `DatasetsToParquet`) **no altera el contenido original**, solo su formato, y por tanto no modifica los t√©rminos de las licencias.  \n",
    "- Los gr√°ficos, tablas y resultados generados a partir de los datasets **s√≠ pueden incluirse libremente en este trabajo**, siempre citando la fuente correspondiente.  \n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Unificaci√≥n y Preprocesado\n",
    "\n",
    "Con el fin de trabajar de manera homog√©nea con todos los datasets, se desarroll√≥ una clase en Python llamada **`DatasetsToParquet`**, cuyo objetivo es:\n",
    "\n",
    "1. **Cargar** los datos originales desde su formato nativo (CSV, NPY, etc.).  \n",
    "2. **Estandarizar** columnas clave como `timestamp` y `anomaly`.  \n",
    "3. **Dividir** los datos en *training*, *validation* y *test* (con un split 60%-40% en validaci√≥n y prueba).  \n",
    "4. **Guardar** los resultados en formato **`.parquet`**, lo que facilita el acceso eficiente y la compatibilidad con librer√≠as como `pandas` y `pyarrow`.\n",
    "\n",
    "De esta manera, todos los conjuntos quedan listos para ser utilizados en la evaluaci√≥n de algoritmos, reduciendo la complejidad derivada de la heterogeneidad de los formatos originales.\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Inspecci√≥n de Datos Procesados\n",
    "\n",
    "Adicionalmente, se implement√≥ la funci√≥n **`inspect_parquet`**, que permite verificar el correcto procesamiento de cada dataset y obtener un resumen inicial:\n",
    "\n",
    "- N√∫mero de filas y columnas.  \n",
    "- Conteo y porcentaje de anomal√≠as.  \n",
    "- Vista previa de las primeras observaciones.  \n",
    "\n",
    "Esto asegura que los datos se encuentran en un estado adecuado antes de iniciar los experimentos.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Consideraciones sobre la validaci√≥n en datos temporales\n",
    "\n",
    "Un aspecto clave de estos datasets es que contienen **series temporales**, por lo que no se pueden aplicar directamente t√©cnicas tradicionales de validaci√≥n como:\n",
    "\n",
    "- **k-fold cross-validation**: romper√≠a la secuencia temporal y provocar√≠a fuga de informaci√≥n del futuro hacia el pasado.  \n",
    "- **Bootstrap est√°ndar**: al re-muestrear observaciones de forma independiente, se pierde la dependencia temporal entre datos consecutivos.  \n",
    "\n",
    "En lugar de ello, la validaci√≥n se plantea con **splits consecutivos** ya definidos en *training*, *validation* y *test*, respetando el orden temporal.  \n",
    "\n",
    "El flujo de trabajo es el siguiente:\n",
    "1. **Entrenamiento** ‚Üí el modelo aprende patrones en el conjunto de entrenamiento.  \n",
    "2. **Validaci√≥n** ‚Üí se ajustan hiperpar√°metros y se seleccionan umbrales usando √∫nicamente datos posteriores al entrenamiento.  \n",
    "3. **Test** ‚Üí se utiliza como evaluaci√≥n final en un conjunto completamente no visto.  \n",
    "\n",
    "Este enfoque se alinea con las buenas pr√°cticas en detecci√≥n de anomal√≠as en series temporales y evita sesgos asociados a t√©cnicas de muestreo tradicionales. En algunos casos, se pueden emplear variantes adaptadas (walk-forward validation, block bootstrap, purged cross-validation), pero siempre respetando la secuencia temporal.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Estrategias de comparaci√≥n de modelos\n",
    "\n",
    "Dado que se pretende evaluar distintos algoritmos (Isolation Forest, autoencoders, Transformers, entre otros), es necesario establecer un conjunto de **m√©tricas comparativas** que permitan medir su desempe√±o en condiciones homog√©neas.  \n",
    "\n",
    "Las m√©tricas seleccionadas incluyen:\n",
    "\n",
    "- **Precision, Recall y F1-score** ‚Üí evaluando los modelos para determinar su porcentaje de fiabilidad.  \n",
    "- **PR-AUC (√Årea bajo la curva Precision-Recall)** ‚Üí m√°s informativa que ROC-AUC en escenarios altamente desbalanceados.  \n",
    "- **NAB Score (Numenta Anomaly Benchmark)** ‚Üí valora detecciones tempranas penalizando falsas alarmas.  \n",
    "- **Tasa de falsas alarmas normalizada (FA/hora o FA/d√≠a)** ‚Üí para medir la estabilidad pr√°ctica del modelo.  \n",
    "- **Tiempo medio de detecci√≥n (MTTD)** ‚Üí cu√°nto tarda un algoritmo en identificar una anomal√≠a desde su inicio.  \n",
    "\n",
    "Adicionalmente, se tendr√° en cuenta la **robustez entre datasets**: un modelo se considerar√° m√°s generalizable si mantiene un rendimiento consistente en diferentes dominios (industrial, espacial, sint√©tico).\n",
    "\n",
    "## üìå Pr√≥ximos pasos\n",
    "\n",
    "En el siguiente cap√≠tulo se presentar√°n los **m√©todos de detecci√≥n de anomal√≠as** que se evaluar√°n sobre estos datasets.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
